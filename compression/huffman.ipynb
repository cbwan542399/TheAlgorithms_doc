{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('myaivenv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4570298ddf55f12d72b384cb5a92401407339203adac8a4a881fb11d70b7d0b5"
   }
  },
  "interpreter": {
   "hash": "4570298ddf55f12d72b384cb5a92401407339203adac8a4a881fb11d70b7d0b5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Huffman  哈夫曼树\n",
    "\n",
    "给定N个权值作为N个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。\n",
    "\n",
    "## 简介\n",
    "在计算机数据处理中，哈夫曼编码使用变长编码表对源符号（如文件中的一个字母）进行编码，其中变长编码表是通过一种评估来源符号出现机率的方法得到的，出现机率高的字母使用较短的编码，反之出现机率低的则使用较长的编码，这便使编码之后的字符串的平均长度、期望值降低，从而达到无损压缩数据的目的。<br>\n",
    "\n",
    "例如，在英文中，$ e $ 的出现机率最高，而 $ z $ 的出现概率则最低。当利用哈夫曼编码对一篇英文进行压缩时，$ e $ 极有可能用一个比特来表示，而 $ z $ 则可能花去 $ 25 $ 个比特（不是 $ 26 $ ）。用普通的表示方法时，每个英文字母均占用一个字节，即 $ 8 $ 个比特。二者相比，$ e $ 使用了一般编码的 $ 1/8 $  的长度，$ z $ 则使用了3倍多。倘若我们能实现对于英文中各个字母出现概率的较准确的估算，就可以大幅度提高无损压缩的比例。<br>\n",
    "\n",
    "哈夫曼树又称最优二叉树，是一种带权路径长度最短的二叉树。所谓树的带权路径长度，就是树中所有的叶结点的权值乘上其到根结点的路径长度（若根结点为0层，叶结点到根结点的路径长度为叶结点的层数）。树的路径长度是从树根到每一结点的路径长度之和，记为 $ WPL=（W_1 \\times L_1+ W_2 \\times L_2 + W_3 \\times L_3+\\cdots +W_n \\times L_n）$，$ N $ 个权值 $ W_i（i=1,2,\\cdots,n）$ 构成一棵有N个叶结点的二叉树，相应的叶结点的路径长度为 $L_i（i=1,2,\\cdots\\,n）$ 。可以证明哈夫曼树的 $ WPL $是最小的。\n",
    "\n",
    "## 历史\n",
    "\n",
    "1951年，哈夫曼在麻省理工学院（MIT）攻读博士学位，他和修读信息论课程的同学得选择是完成学期报告还是期末考试。导师罗伯特·法诺（Robert Fano）出的学期报告题目是：查找最有效的二进制编码。由于无法证明哪个已有编码是最有效的，哈夫曼放弃对已有编码的研究，转向新的探索，最终发现了基于有序频率二叉树编码的想法，并很快证明了这个方法是最有效的。哈夫曼使用自底向上的方法构建二叉树，避免了次优算法香农-范诺编码（Shannon–Fano coding）的最大弊端──自顶向下构建树。<br>\n",
    "\n",
    "1952年，于论文《一种构建极小多余编码的方法》（A Method for the Construction of Minimum-Redundancy Codes）中发表了这个编码方法。\n",
    "\n",
    "## 应用\n",
    "- 1、哈夫曼编码 <br>\n",
    "在数据通信中，需要将传送的文字转换成二进制的字符串，用0，1码的不同排列来表示字符。例如，需传送的报文为“AFTER DATA EAR ARE ART AREA”，这里用到的字符集为“A，E，R，T，F，D”，各字母出现的次数为{8，4，5，3，1，1}。现要求为这些字母设计编码。要区别6个字母，最简单的二进制编码方式是等长编码，固定采用3位二进制，可分别用000、001、010、011、100、101对“A，E，R，T，F，D”进行编码发送，当对方接收报文时再按照三位一分进行译码。显然编码的长度取决报文中不同字符的个数。若报文中可能出现26个不同字符，则固定编码长度为5。然而，传送报文时总是希望总长度尽可能短。在实际应用中，各个字符的出现频度或使用次数是不相同的，如A、B、C的使用频率远远高于X、Y、Z，自然会想到设计编码时，让使用频率高的用短码，使用频率低的用长码，以优化整个报文编码。<br>\n",
    "\n",
    " - 哈夫曼树 <br>\n",
    "为使不等长编码为前缀编码(即要求一个字符的编码不能是另一个字符编码的前缀)，可用字符集中的每个字符作为叶子结点生成一棵编码二叉树，为了获得传送报文的最短长度，可将每个字符的出现频率作为字符结点的权值赋予该结点上，显然字使用频率越小权值越小，权值越小叶子就越靠下，于是频率小编码长，频率高编码短，这样就保证了此树的最小带权路径长度效果上就是传送报文的最短长度。因此，求传送报文的最短长度问题转化为求由字符集中的所有字符作为叶子结点，由字符出现频率作为其权值所产生的哈夫曼树的问题。利用哈夫曼树来设计二进制的前缀编码，既满足前缀编码的条件，又保证报文编码总长最短。<br>\n",
    " - 哈夫曼静态编码：<br>\n",
    "它对需要编码的数据进行两遍扫描：<br>\n",
    "第一遍统计原数据中各字符出现的频率，利用得到的频率值创建哈夫曼树，并必须把树的信息保存起来，即把字符$ 0-255(2^8=256) $的频率值以2-4BYTES的长度顺序存储起来，（用4Bytes的长度存储频率值，频率值的表示范围为$ 0--2^32-1 $ ，这已足够表示大文件中字符出现的频率了）以便解压时创建同样的哈夫曼树进行解压；<br>\n",
    "第二遍则根据第一遍扫描得到的哈夫曼树进行编码，并把编码后得到的码字存储起来。<br>\n",
    " - 哈夫曼动态编码：<br>\n",
    "动态哈夫曼编码使用一棵动态变化的哈夫曼树，对第t+1个字符的编码是根据原始数据中前t个字符得到的哈夫曼树来进行的，编码和解码使用相同的初始哈夫曼树，每处理完一个字符，编码和解码使用相同的方法修改哈夫曼树，所以没有必要为解码而保存哈夫曼树的信息。编码和解码一个字符所需的时间与该字符的编码长度成正比，所以动态哈夫曼编码可实时进行。<br>\n",
    "- 2、哈夫曼译码 <br>\n",
    "在通信中，若将字符用哈夫曼编码形式发送出去，对方接收到编码后，将编码还原成字符的过程，称为哈夫曼译码。<br>\n",
    "\n",
    "## 基本术语\n",
    "哈夫曼树又称为最优树. <br>\n",
    "- 1、路径和路径长度 <br>\n",
    "在一棵树中，从一个结点往下可以达到的孩子或孙子结点之间的通路，称为路径。通路中分支的数目称为路径长度。若规定根结点的层数为1，则从根结点到第L层结点的路径长度为L-1。\n",
    "- 2、结点的权及带权路径长度<br>\n",
    "哈夫曼树<br>\n",
    "若将树中结点赋给一个有着某种含义的数值，则这个数值称为该结点的权。结点的带权路径长度为：从根结点到该结点之间的路径长度与该结点的权的乘积。<br>\n",
    "- 3、树的带权路径长度 <br>\n",
    "树的带权路径长度规定为所有叶子结点的带权路径长度之和，记为WPL。<br>\n",
    "构造 <br>\n",
    "哈夫曼树的构造 <br>\n",
    "假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 $ w_1、w_2、\\cdots,w_n $ ，则哈夫曼树的构造规则为：<br>\n",
    " - (1) 将$ w_1、w_2、\\cdots，w_n$ 看成是有 $ n $ 棵树的森林(每棵树仅有一个结点)；\n",
    " - (2) 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和； <br>\n",
    " - (3)从森林中删除选取的两棵树，并将新树加入森林；<br>\n",
    " - (4)重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。<br>\n",
    "\n",
    "## 多叉哈夫曼树 <br>\n",
    "哈夫曼树也可以是 $ k $ 叉的，只是在构造$ k $ 叉哈夫曼树时需要先进行一些调整。构造哈夫曼树的思想是每次选k个权重最小的元素来合成一个新的元素，该元素权重为 $ k $ 个元素权重之和。但是当$ k $ 大于2时，按照这个步骤做下去可能到最后剩下的元素少于$ k $个。解决这个问题的办法是假设已经有了一棵哈夫曼树(且为一棵满k叉树)，则可以计算出其叶节点数目为$ (k-1)nk+1 $ ,式子中的 $ nk $ 表示子节点数目为k的节点数目。于是对给定的n个权值构造k叉哈夫曼树时,可以先考虑增加一些权值为0的叶子节点，使得叶子节点总数为$ (k-1)nk+1 $ 这种形式,然后再按照哈夫曼树的方法进行构造即可。<br>\n",
    "\n",
    "## 实现方法 <br>\n",
    "数据压缩 <br>\n",
    "实现哈夫曼编码的方式主要是创建一个二叉树和其节点。这些树的节点可以存储在数组里，数组的大小为符号（symbols）数的大小n，而节点分别是终端节点（叶节点）与非终端节点（内部节点）。<br>\n",
    "一开始，所有的节点都是终端节点，节点内有三个字段：<br>\n",
    " - 1.符号（Symbol）<br>\n",
    " - 2.权重（Weight、Probabilities、Frequency）<br>\n",
    " - 3.指向父节点的链接（Link to its parent node）<br>\n",
    "而非终端节点内有四个字段：<br>\n",
    " - 1.权重（Weight、Probabilities、Frequency）<br>\n",
    " - 2.指向两个子节点的链接（Links to two child node）<br>\n",
    " - 3.指向父节点的链接（Link to its parent node）<br>\n",
    "基本上，我们用'0'与'1'分别代表指向左子节点与右子节点，最后为完成的二叉树共有n个终端节点与n-1个非终端节点，去除了不必要的符号并产生最佳的编码长度。<br>\n",
    "过程中，每个终端节点都包含着一个权重（Weight、Probabilities、Frequency），两两终端节点结合会产生一个新节点，新节点的权重是由两个权重最小的终端节点权重之总和，并持续进行此过程直到只剩下一个节点为止。<br>\n",
    "实现哈夫曼树的方式有很多种，可以使用优先队列（Priority Queue）简单达成这个过程，给与权重较低的符号较高的优先级（Priority），算法如下：<br>\n",
    " - ⒈把n个终端节点加入优先队列，则n个节点都有一个优先权Pi，1 ≤ i ≤ n <br>\n",
    " - ⒉如果队列内的节点数>1，则：<br>\n",
    "  - ⑴从队列中移除两个最小的Pi节点，即连续做两次remove（min（Pi）, Priority_Queue)\n",
    "  - ⑵产生一个新节点，此节点为（1）之移除节点之父节点，而此节点的权重值为（1）两节点之权重和<br>\n",
    "  - ⑶把（2）产生之节点加入优先队列中 <br>\n",
    " - ⒊最后在优先队列里的点为树的根节点（root） <br>\n",
    "而此算法的时间复杂度（Time Complexity）为O（n log n）；因为有n个终端节点，所以树总共有2n-1个节点，使用优先队列每个循环须O（log n）。<br>\n",
    "此外，有一个更快的方式使时间复杂度降至线性时间（Linear Time）O（n），就是使用两个队列（Queue）创建哈夫曼树。\n",
    "第一个队列用来存储n个符号（即n个终端节点）的权重，\n",
    "第二个队列用来存储两两权重的合（即非终端节点）。此法可保证第二个队列的前端（Front）权重永远都是最小值，且方法如下：<br>\n",
    " - ⒈把n个终端节点加入第一个队列（依照权重大小排列，最小在前端）<br>\n",
    " - ⒉如果队列内的节点数>1，则：<br>\n",
    "  - ⑴从队列前端移除两个最低权重的节点 <br>\n",
    "  - ⑵将（1）中移除的两个节点权重相加合成一个新节点 <br>\n",
    "  - ⑶加入第二个队列\n",
    " - ⒊最后在第一个队列的节点为根节点\n",
    "虽然使用此方法比使用优先队列的时间复杂度还低，但是注意此法的第1项，节点必须依照权重大小加入队列中，如果节点加入顺序不按大小，则需要经过排序，则至少花了O（n log n）的时间复杂度计算。\n",
    "但是在不同的状况考量下，时间复杂度并非是最重要的，如果我们考虑英文字母的出现频率，变量n就是英文字母的26个字母，则使用哪一种算法时间复杂度都不会影响很大，因为n不是一笔庞大的数字。\n",
    "\n",
    "## 数据解压缩\n",
    "\n",
    "简单来说，哈夫曼码树的解压缩就是将得到的前置码（Prefix Huffman code）转换回符号，通常借由树的追踪（Traversal），将接收到的比特串（Bits stream）一步一步还原。但是要追踪树之前，必须要先重建哈夫曼树；某些情况下，如果每个符号的权重可以被事先预测，那么哈夫曼树就可以预先重建，并且存储并重复使用，否则，发送端必须预先发送哈夫曼树的相关信息给接收端  。<br>\n",
    "最简单的方式，就是预先统计各符号的权重并加入至压缩之比特串，但是此法的运算量花费相当大，并不适合实际的应用。若是使用Canonical encoding，则可精准得知树重建的数据量只占B2^B比特（其中B为每个符号的比特数（bits））。如果简单将接收到的比特串一个比特一个比特的重建，例如：'0'表示父节点，'1'表示终端节点，若每次读取到1时，下8个比特则会被解读是终端节点（假设数据为8-bit字母），则哈夫曼树则可被重建，以此方法，数据量的大小可能为2~320字节不等。虽然还有很多方法可以重建哈夫曼树，但因为压缩的数据串包含\"traling bits\"，所以还原时一定要考虑何时停止，不要还原到错误的值，如在数据压缩时时加上每笔数据的长度等。<br>\n",
    "\n",
    "## 示例\n",
    "当有100个位子，有白色占60%、咖啡色占20%，蓝色和红色各占10%，则该如何分配才能最优化此座位?  <br>\n",
    "- (a)direct: <br>\n",
    "假设结果为：白色为00、咖啡色01，蓝色10和红色11个 bits则结果为:100*2 = 200bits <br>\n",
    "- (b)huffman code: (must be satisfy the following conditions，if not change the node) <br>\n",
    " - (1) 所有码皆在Coding Tree的端点，再下去没有分枝(满足一致解码跟瞬间解码) <br>\n",
    " - (2) 机率越大，code length越短；机率越小，code length越长 <br>\n",
    " - (3) 假设是第L层的node，是第L+1层的node <br>\n",
    "则必须满足 <br>\n",
    "假设结果为：白色占0、咖啡色10，蓝色110和红色111个bits <br>\n",
    "则结果为:60*1+20*2+20*3=160bits <br>\n",
    "相互比较两个结果huffman code 整整少了40bits的存储空间。<br>\n",
    "\n",
    "## 代码\n",
    "[huffman.py]{..\\src\\compression\\huffman.py}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare\n",
    "   1. sys.path 中增加 TheAlgorithms\\src 子模块\n",
    "\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append('E:\\dev\\AI\\TheAlgorithms\\src')\n"
   ]
  },
  {
   "source": [
    "## 案例一： all_rotations\n",
    "```\n",
    "all_rotations(s: str) -> list[str]:\n",
    "\"\"\"\n",
    ":param s: The string that will be rotated len(s) t\n",
    ":return: A list with the rotations.\n",
    ":raises TypeError: If s is not an instance of str.\n",
    "\"\"\"\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['^BANANA|', 'BANANA|^', 'ANANA|^B', 'NANA|^BA', 'ANA|^BAN', 'NA|^BANA', 'A|^BANAN', '|^BANANA']\n['a_asa_da_casa', '_asa_da_casaa', 'asa_da_casaa_', 'sa_da_casaa_a', 'a_da_casaa_as', '_da_casaa_asa', 'da_casaa_asa_', 'a_casaa_asa_d', '_casaa_asa_da', 'casaa_asa_da_', 'asaa_asa_da_c', 'saa_asa_da_ca', 'aa_asa_da_cas']\n['panamabanana', 'anamabananap', 'namabananapa', 'amabananapan', 'mabananapana', 'abananapanam', 'bananapanama', 'ananapanamab', 'nanapanamaba', 'anapanamaban', 'napanamabana', 'apanamabanan']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\n  ['panamabanana', 'anamabananap', 'namabananapa', 'amabananapan'\\n  'mabananapana', 'abananapanam', 'bananapanama', 'ananapanamab',\\n  'nanapanamaba', 'anapanamaban', 'napanamabana', 'apanamabanan']\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from compression.huffman import huffman\n",
    "\"\"\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}